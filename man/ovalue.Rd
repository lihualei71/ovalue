% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/main.R
\name{ovalue}
\alias{ovalue}
\title{O-values of Observational Studies}
\usage{
ovalue(
  T = NULL,
  X = NULL,
  formula = NULL,
  data = NULL,
  alpha = 0.05,
  type = c("ATE", "ATT", "ATC"),
  scorefuns = c("rf", "gbm"),
  sw = rep(1, length(scorefuns)),
  methods = c("ROC", "EBenn"),
  mw = rep(1, length(methods)),
  datasplit = FALSE,
  trainprop = 0.5,
  nreps = 50,
  drq = 0.5,
  drcorrect = FALSE,
  verbose = TRUE,
  return_list = FALSE,
  ...
)
}
\arguments{
\item{T}{logical vector or a factor/vector encoded by 0 and 1. Treatment assignment}

\item{X}{matrix or data.frame. Covariate}

\item{formula}{formula object. See Details}

\item{data}{data.frame. See Details}

\item{alpha}{numeric. Confidence level}

\item{type}{vector of strings. Types of overlap condition to be considered. Currently support "ATE", "ATT" and "ATC"}

\item{scorefuns}{vector of strings or functions. See Details}

\item{sw}{vector of non-negative numbers. See Details}

\item{methods}{vector of strings or functions. See Details}

\item{mw}{vector of non-negative numbers. See Details}

\item{datasplit}{logical. Indicate whether data splitting is performed.}

\item{trainprop}{numeric. Proportion of training samples}

\item{nreps}{an integer. Number of times for data splitting}

\item{drq}{numeric. The quantile at which the O-values are reported. See Details}

\item{drcorrect}{logical. Indicate whether the confidence level needs to be corrected for derandomization. See Details}

\item{verbose}{logical. Indicate whether relevant information is outputted to the console}

\item{return_list}{logical. Indicate whether the O-values for each split are returned.}

\item{...}{Other arguments passed into \code{scorefuns}}
}
\value{
\item{ATE/ATT/ATC}{ median of O-values for all splitted data for ATE/ATT/ATC.}
\item{etalist}{ optional (only returned when \code{return_list = TRUE}). List of O-values for each splitted data. Each entry corresponds to a type of overlap condition.}
}
\description{
\code{ovalue} is a framework to calculate O-values of observational studies allowing for arbitrary classifiers to calculate 1-d scores.
}
\details{
\code{ovalue} provides a bunch of user-friendly wrappers and a flexible framework that allows for arbitrary classifiers. It also supports using multiple classifiers with each classifier being assigned a fraction of confidence budget. The argument \code{scorefuns} gives either one or multiple classifiers and the argument \code{sw} gives their weights. Specifically, the algorithm will assign \code{sw[i] / sum(sw)} fraction of confidence budget to the i-th method.

Each element of \code{scorefuns} can be a valid string, including
\itemize{
\item "logistic" for logistic regression,
\item "lasso" for L1-penalized logistic regression,
\item "gam" for generalized additive model,
\item "gbm" for generalized boosting machine,
\item "rf" for random forest,
}

or a function object whose inputs must include
\itemize{
\item "T" for treatment vector, must be a logical vector or a factor/vector encoded by 0 and 1,
\item "X" for covariates, must be a vector/matrix/data.frame,
\item "trainid" for the index of training samples, must be a logical vector or a vector of integers.
\item "testid" for the index of testing samples, must be a logical vector or a vector of integers. "testid" is allowed to overlap with "trainid".
The default setting is \code{scorefuns = c("rf", "gbm"), sw = c(1, 1)}.
}

\code{ovalue} supports two types of data inputs: (1) \code{T} and \code{X} or (2) \code{formula} and \code{data}. One of the pair has to be specified.

Similar to the classifiers, \code{ovalue} provides a bunch of testing methods and a flexible framework that allows for user-specified external testing methods. It also supports hybrid version of multiple testing methods with each method assigned a fraction of confidence budget. The argument \code{methods} gives either one or multiple testing methods and the argument \code{mw} gives their weights. Specifically, the algorithm will assign \code{mw[i] / sum(mw)} fraction of confidence budget to the i-th test.

Each element of \code{methods} can be a valid string, including
\itemize{
\item "ROC" for ROC bound,
\item "EBenn" for \eqn{$\chi^2$} bound based on Empirical Bennett inequality,
}

or a function object whose inputs must include
\itemize{
\item "T" for treatment vector, must be a logical vector or a factor/vector encoded by 0 and 1,
\item "score" for the univariate scores, must be a vector with the same length as "T",
\item "delta" for the confidence level, must be a real number in \eqn{[0, 1]}.
The default setting is \code{scorefuns = c("ROC", "EBenn"), sw = c(1, 1)}.
}

Derandomization step is crucial to reduce the external randomness from data splitting. \code{ovalue} calculate O-values for \code{nreps} data splits and report the \code{drq}-th quantile. If the confidence level for each split is \eqn{$\beta$}, it is guaranteed that the coverage is at least \eqn{$\beta / drq$}. To guarantee the coverage in worst case, \code{ovalue} corrects \code{alpha} to \code{alpha} * \code{drq}, if \code{drcorrect = TRUE} by default. In practice, users might awant to avoid this level of correction because each O-value is conservative and the overall coverage will still be guaranteed even without the correction.
}
\examples{
\donttest{# Generate data from a logistic model
set.seed(1)
n <- 1000
p <- 50
X <- matrix(stats::rnorm(n * p), n, p)
beta <- rep(1 / sqrt(p), p)
probs <- 1 / (1 + exp(-X \%*\% beta))
T <- stats::runif(n) <= probs
data <- data.frame(T = T, X)

# Calculate the O-value with inputs \code{T} and \code{X}
set.seed(1)
ovalue(T, X, scorefuns = "gbm")

# Calculate the O-value with inputs \code{formula} and \code{data}
set.seed(1)
ovalue(formula = T ~ ., data = data, scorefuns = "gbm")
}

}
